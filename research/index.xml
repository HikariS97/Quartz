<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Researches on</title><link>https://hikaris97.github.io/Quartz/research/</link><description>Recent content in Researches on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://hikaris97.github.io/Quartz/research/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/calibration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/calibration/</guid><description>一些资源汇总 https://github.com/SoundMetrics/aris-file-sdk/tree/master/beam-width-metrics 中有官方给出的 ARIS 声呐的 beam pattern 的数据。 https://github.com/pvazteixeira/multibeam 给出了处理 DIDSON mapping 的方法。给出的 DIDSON 的 fov 是 0.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/detection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/detection/</guid><description>Paper List: 与声呐相关的目标/纹理/显著检测 不仅仅是多波束前视声呐，也包含侧扫、合成孔径等
[[1984 JASA T.K. Stanton Sonar Estimates of Seafloor Microroughness.pdf]]
[[2002 Ronald Kessel Using Sonar Speckle to Identify Regions of Interest and for Mine Detection.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Flow-based/main/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Flow-based/main/</guid><description>光流 aperture problem Angular Error (AE) and the Endpoint Error (EPE)</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Kio-Kim/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Kio-Kim/note/</guid><description>[[2004 Acoustic Camera Image Mosaicing and Super-resolution.pdf]] OCEANS 2004
进行预处理平衡 insonification profile。用高斯核平滑图像作为 profile 的估计，添加正则项防止低反射区域数值爆炸； 检测采用 Harris 角点，确定一个小图像 patch，在待配准图像同点周围利用 cross-correlation 暴力搜索。 融合 SNR 最大化 最大似然 （注意，上述是递进关系。有一些先验假定，说不清楚） [[2004 Image Mosaicing of Noisy Acoustic Camera.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/odo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/odo/</guid><description>2D 前视声呐里程计估计 相关工作 MIT &amp;amp; CMU [[2010 IROS Johannsson.pdf]] [[2012 IJRR ShipHull.pdf | 2012 IJRR ShipHull]] 结合阴影聚类点块，利用 NDT 方法避免特征的匹配。用了 Pose Graph 但没有写如何获得配准的误差估计，也没有写如何利用传感器信息获取得到 loop closure。（有可能是通过估计的位置搜索半径）</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/some-math/Speckle-Noise-Related-Statistics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/some-math/Speckle-Noise-Related-Statistics/</guid><description>Weibull Distribution Gamma Function Rayleigh Distribution</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Stevens-Institute-of-Technology/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Stevens-Institute-of-Technology/note/</guid><description>[[2020 IROS John McConnell Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction.pdf]] 两个 Oculus 视角正交防止，集成于 BlueROV2。Association 仅作用于交叉视场。</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Sweden/John-Folkesson/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Sweden/John-Folkesson/note/</guid><description>[[2022 Submit JOE Neural Shape-from-Shading for Survey-Scale Self-Consistent Bathymetry from Sidescan.pdf]] 依赖于高精度定位信息（NOTE: iNeRF，同时估计？） Loss Function: $$ \mathcal{L}=\mathcal{L}{\nabla}+\alpha \mathcal{L}H $$ 其中，$\mathcal{L}H$ 为高度计数据与预测的差值，$\mathcal{L}{\Delta}$ 则复杂一些，也重要一些： $$ \mathcal{L}{\nabla}=\frac{1}{\left|\left{I{i, n}\right}\right|} \sum \left| \tilde{I}{i, n}-I{i, n} \right| $$ 将 $\text{ping}i$ 的 $\text{bin}n$ 的点 $p{i, n}$ 用 $\phi{\text{俯仰角}}$ 参数化，得 $p_{i, n} (\phi)$。并假设表示地面的函数在该表示下单调。</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Universidade-Federal-de-Rio-Grande/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Universidade-Federal-de-Rio-Grande/note/</guid><description>场景：partially structured scene
[[2015 LARS A Topological Descriptor of Acoustic Images for Navigation and Mapping.pdf]] 用阈值的方式找出兴趣点，扩展成高斯椭圆形成节点，暴力求解图结构的相似性。算法结果仅对 match 解释，没有里程计、回环检测等内容
[[2016 OCEANS A Modified topological descriptor for forward looking sonar images.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Florence/main/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Florence/main/</guid><description>2018 AUV A Forward Looking Sonar Based System for Underwater Mosaicing and Acoustic Odometry 拼图 测速 FeelHippo AUV FeelHippo AUV 由佛罗伦萨大学工业工程学院建造，小型、短途、浅海，用于参加面向学生的国际机器人比赛。搭载</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Miami/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Miami/note/</guid><description>Shahriar Negahdaripour [[1998 OCEANS Use of Forward Scan Sonar Images for Positioning and Navigation by an AUV.pdf]] 使用了 220KHz 的自制声呐对沉船拍了 50 张。初步使用 Optical Flow 进行位移的估计</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6/note/</guid><description>[[2012 Calibration_and_Mosaicing_of_Forward-Scan_Sonar_DIDSON_Images.pdf]] 无 Calibration 的内容。
若 edge point，保留；否则，加权平均。然而，未说明权重的取值方式。 [[2012 Detection and Tracking of Underwater Object Based on Forward-Scan Sonar.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E5%93%88%E5%B7%A5%E7%A8%8B/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E5%93%88%E5%B7%A5%E7%A8%8B/note/</guid><description>[[2016 OCEANS Forward-looking_sonar_image_registration_using_polar_transform.pdf]]
[[2017 IET-RadarSonarNavi NSCT‐based fusion method for forward‐looking sonar image mosaic.pdf]] NSCT 变换
[[2022 Sensors Journal Harbin Beam-Domain_Image_Mosaic_of_Forward-Looking_Sonar_using_Expression_Domain_Mapping_Model.pdf]] JOE optical flow 低配。</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/feature-extraction/traditional-methods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/feature-extraction/traditional-methods/</guid><description>Harris SIFT</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/graph-matching/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/graph-matching/note/</guid><description>[[2005 ICCV A Spectral Technique for Correspondence Problems Using Pairwise Constraints.pdf]] 谱方法指的是基于谱分解的方法，也就是基于特征值分解的方法。
介绍 不仅考虑特征点描述子的匹配程度，还考虑特征点间几何匹配程度。不仅可以一对一配准，也可以允许一对多的配准，如：形状匹配。
问题描述 给定两组特征点 $P$，包含 $n_P$ 数据特征，以及 $Q$，包含 $n_Q$ 模型特征，以及相关性映射 $C$ 包含点与点的配对关系 $(i, i&amp;rsquo;)$，$i \in P$ 且 $i&amp;rsquo; \in Q$。$P$ 与 $Q$ 中的点属于 $C$ 的为 inliers，反之，$outliers$。 将一个点对成为 assignment，有 $a = (i, i&amp;rsquo;)$。括号实则隐含了一个计算 associated score 或称 affinity 的函数。同样，affinity 也可用来描述点 $(i, j) \in P$ 与 $(i&amp;rsquo;, j&amp;rsquo;) \in Q$ 的相似度。 假设，有 $L$ (list) 包含 $n$ 个待评估的 $a$，则可形成矩阵 $M$，其主对角线上为点与点的相似度，其余部分为边的相似度。$M$ 为非负对称阵。</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/loop-closure/Korea/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/loop-closure/Korea/note/</guid><description>[[2018 IROS Scan Context &amp;mdash; Egocentric Spatial Descriptor for Place Recognition within 3D Point Cloud Map.pdf]] 核心思想：
获取scan context。在声呐、雷达的情况下，本身获得的就是 angle-range 的图片，只需要 max-downsample 即可。文章对点云做了一些扰动，获得更多的 scan context 增强鲁棒性； colunm-wise 比对然后相加。认为只有 colunm-shift，而 row-order 基本不变。（不太站得住脚。）利用 colunm-shifted-scan-context 暴力得到最相近的分数，来判断是否回环。（不如用 FFT？） two-phase detection 提取 ring-key，方法是每一个 ring 的占空比。其是 rotational-invariant。 再暴力搜索</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/note/</guid><description>IROS 2022 Workshop Design of a bi-monocular Visual Odometry System for Lava Tubes exploration
2022 IoT A Time-saving Path Planning Scheme for Autonomous Underwater Vehicles with Complex Underwater Conditions</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Heriot-Watt/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Heriot-Watt/note/</guid><description>[[2020 IROS RadarSLAM_Radar_based_Large-Scale_SLAM_in_All_Weathers.pdf]]
特征提取：利用 SURF 提取点，加入 Motion Prior 进行限制，利用描述子配准，用边误差与一个预设的 $\delta_c$ 比较抵消外点； 局部优化：局部 BA 回环检测： 词袋模型在视觉中有很好的效果，但在 Radar 数据下并非如此，原因如下： 描述子重复 多径进一步加剧描述子的模糊 视觉转换导致场景剧烈变化 图像转换成点云，再一次提取点，形成旋转不变描述子 优化：g2o 文章构建基于 ORB-SLAM 单从里程计的角度来说，并不一定[[2018 ICRA Precise Ego-Motion Estimation with Millimeter-Wave Radar under Diverse and Challenging Conditions.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Korea/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Korea/note/</guid><description>[[2020 ICRA PhaRaO_Direct_Radar_Odometry_using_Phase_Correlation.pdf]] tricks 结合。其中，local graph optimization 可移植到前视声呐。</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/University-of-Oxford/note/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/University-of-Oxford/note/</guid><description>Sarah Huiyi Cen 关于雷达运动估计的文章只有两篇，目前（2022）在 MIT 做博后已转深度学习研究。
采用的 FMCW 角度采样点 399，距离采样点 2000，距离分辨率 0.25米。水平方向波束宽度 2°，竖直方向波束宽度 25°，采样速率 4Hz。
[[2018 ICRA Precise Ego-Motion Estimation with Millimeter-Wave Radar under Diverse and Challenging Conditions.</description></item><item><title/><link>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Rolling-Shutter-Odometry/Rolling-Shutter-Camera-ARIS-Camera/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hikaris97.github.io/Quartz/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Rolling-Shutter-Odometry/Rolling-Shutter-Camera-ARIS-Camera/</guid><description>相机模型、李代数等复习 **$S O(3)$ $\boldsymbol{R}(t)=\exp \left(\phi_{0}^{\wedge} t\right)$ $\phi$ 就是对应的 $\mathfrak{s o}(3)$ 用 $\Phi$ 表示 $\phi$ 的反对称阵
$SE(3)$ $$ \mathfrak{s e}(3)=\left{\xi=\left[\begin{array}{c} \rho \ \phi \end{array}\right] \in \mathbb{R}^{6}, \rho \in \mathbb{R}^{3}, \phi \in \mathfrak{s o}(3), \xi^{\wedge}=\left[\begin{array}{cc} \phi^{\wedge} &amp;amp; \rho \ 0^{T} &amp;amp; 0 \end{array}\right] \in \mathbb{R}^{4 \times 4}\right} $$ 从 $\mathbb{R}^6 \rightarrow \mathbb{R}^{4 \times 4}$</description></item></channel></rss>