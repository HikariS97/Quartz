{"/":{"title":"🪴 Quartz 3.3","content":"\nHost your second brain and [digital garden](https://jzhao.xyz/posts/networked-thought) for free. Quartz features\n\n1. Extremely fast natural-language [[notes/search]]\n2. Customizable and hackable design based on [Hugo](https://gohugo.io/)\n3. Automatically generated backlinks, link previews, and local graph\n4. Built-in [[notes/CJK + Latex Support (测试) | CJK + Latex Support]] and [[notes/callouts | Admonition-style callouts]]\n5. Support for both Markdown Links and Wikilinks\n\nCheck out some of the [amazing gardens that community members](notes/showcase.md) have published with Quartz or read about [why I made Quartz](notes/philosophy.md) to begin with.\n\n## Get Started\n\u003e 📚 Step 1: [Setup your own digital garden using Quartz](notes/setup.md)\n\nReturning user? Figure out how to [[notes/updating|update]] your existing Quartz garden.\n\nIf you prefer browsing the contents of this site through a list instead of a graph, you see a list of all [setup-related notes](/tags/setup).\n\n### Troubleshooting\n- 🚧 [Troubleshooting and FAQ](notes/troubleshooting.md)\n- 🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n- 👀 [Discord Community](https://discord.gg/cRFFHYye7t)\n\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Rolling-Shutter-Odometry/Rolling-Shutter-Camera-ARIS-Camera":{"title":"Rolling Shutter Camera (ARIS Camera)","content":"# 相机模型、李代数等复习\n\n**$S O(3)$\n$\\boldsymbol{R}(t)=\\exp \\left(\\phi_{0}^{\\wedge} t\\right)$\n$\\phi$ 就是对应的 $\\mathfrak{s o}(3)$ \n用 $\\Phi$ 表示 $\\phi$ 的反对称阵\n\n$SE(3)$\n$$\n\\mathfrak{s e}(3)=\\left\\{\\xi=\\left[\\begin{array}{c}\n\\rho \\\\\n\\phi\n\\end{array}\\right] \\in \\mathbb{R}^{6}, \\rho \\in \\mathbb{R}^{3}, \\phi \\in \\mathfrak{s o}(3), \\xi^{\\wedge}=\\left[\\begin{array}{cc}\n\\phi^{\\wedge} \u0026 \\rho \\\\\n0^{T} \u0026 0\n\\end{array}\\right] \\in \\mathbb{R}^{4 \\times 4}\\right\\}\n$$\n从 $\\mathbb{R}^6 \\rightarrow \\mathbb{R}^{4 \\times 4}$\n \n\n ","lastmodified":"2023-04-18T08:00:06.327982874Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/feature-extraction/traditional-methods":{"title":"traditional methods","content":"# Harris\n\n# SIFT\n","lastmodified":"2023-04-18T08:00:06.327982874Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/graph-matching/note":{"title":"note","content":"[[2005 ICCV A Spectral Technique for Correspondence Problems Using Pairwise Constraints.pdf]]\n谱方法指的是基于谱分解的方法，也就是基于特征值分解的方法。\n## 介绍\n不仅考虑特征点描述子的匹配程度，还考虑特征点间几何匹配程度。不仅可以一对一配准，也可以允许一对多的配准，如：形状匹配。\n\n## 问题描述\n给定两组特征点 $P$，包含 $n_P$ 数据特征，以及 $Q$，包含 $n_Q$ 模型特征，以及相关性映射 $C$ 包含点与点的配对关系 $(i, i')$，$i \\in P$ 且 $i' \\in Q$。$P$ 与 $Q$ 中的点属于 $C$ 的为 *inliers*，反之，$outliers$。\n将一个点对成为 *assignment*，有 $a = (i, i')$。括号实则隐含了一个计算 associated score 或称 *affinity* 的函数。同样，*affinity* 也可用来描述点 $(i, j) \\in P$ 与 $(i', j') \\in Q$ 的相似度。\n假设，有 $L$ (list) 包含 $n$ 个待评估的 $a$，则可形成矩阵 $M$，其主对角线上为点与点的相似度，其余部分为边的相似度。$M$ 为非负对称阵。\n\n## 方法\n设 $x$ 为指示向量，$x(a) \\in \\{ 0, 1 \\}$ 表示 $a$ 是否属于 $C$。从 $M$ 中挑选出所有与 *inliers*  相关的量的和，并使其相关性最大，得：\n$$\nS = x^T M x\n$$\n为找到最优的 $x^*$，有：\n$$\nx^*=\\operatorname{argmax}\\left(x^T M x\\right)\n$$\n$S$ 的值依赖于三点：\n1. 点的数量；\n2. 边的数量；\n3. 边的质量。\n*为什么没有点的质量？因为似乎点本身的配准程度仅作为点数量的初筛，不作为 graph matching 的指标。*\n\n将 $x \\in \\{ 0, 1 \\}$ 松弛成 $x \\in [0, 1]$，并归一化。由 *Raleigh's ratio theorem* 得知 $x^*$ 来自于 $x^T M x$ 的最大特征向量。由于 $M$ 为非负矩阵，根据 *Perron-Frobenius theorem* 得知 $x^*$ 的值仍然处于 $[0, 1]$ 区间中。\n\n文章所提出方法的复杂度优势主要来源于舍弃了一对一匹配约束（*为什么？*）*，与 $x$ 的整数约束。\n\n得到了 $x^* \\in [0, 1]$ 之后利用贪婪算法回避外点。贪婪算法的步骤如下：\n1. 已得到 $x^* \\in [0, 1]$，初始化 $\\boldsymbol{x} = \\bf{0}^{n \\times 1}$ ；\n2. 选取 $x^*$ 中分数最高的，若为 $0$ 则停止。不然，将 $\\boldsymbol{x}$ 对应位置设为 $1$，并将点移出 $L$；\n3. 移除所有的 $(i, k)$。当具有一对一限制时，移除所有的 $(q, i^{'})$；\n4. 知道 $L$ 为空。\n\n## 稳定性分析\n对非结构性噪声较鲁棒，对结构性噪声不鲁棒，如对称点，就容易产生误匹配。\n\n## 复杂度分析\n非负稀疏对称阵求解主特征向量：$O\\left(n^{3 / 2}\\right)$\n矩阵维度通常不会很大\n\n## 实验\n","lastmodified":"2023-04-18T08:00:06.327982874Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/loop-closure/Korea/note":{"title":"note","content":"[[2018 IROS Scan Context --- Egocentric Spatial Descriptor for Place Recognition within 3D Point Cloud Map.pdf]]\n核心思想：\n1. 获取***scan context***。在声呐、雷达的情况下，本身获得的就是 ***angle-range*** 的图片，只需要 ***max-downsample*** 即可。文章对点云做了一些扰动，获得更多的 ***scan context*** 增强鲁棒性；\n2. ***colunm-wise*** 比对然后相加。认为只有 colunm-shift，而 row-order 基本不变。（不太站得住脚。）利用 colunm-shifted-scan-context 暴力得到最相近的分数，来判断是否回环。（不如用 FFT？）\n3. two-phase detection\n\t1. 提取 ring-key，方法是每一个 ring 的占空比。其是 rotational-invariant。\n\t2. 再暴力搜索","lastmodified":"2023-04-18T08:00:06.327982874Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/note":{"title":"note","content":"IROS 2022 Workshop Design of a bi-monocular Visual Odometry System for Lava Tubes exploration\n\n2022 IoT A Time-saving Path Planning Scheme for Autonomous Underwater Vehicles with Complex Underwater Conditions\n\n2022 Virtual Underwater Datasets for Autonomous Inspections","lastmodified":"2023-04-18T08:00:06.327982874Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Heriot-Watt/note":{"title":"note","content":"[[2020 IROS RadarSLAM_Radar_based_Large-Scale_SLAM_in_All_Weathers.pdf]]\n1. 特征提取：利用 SURF 提取点，加入 Motion Prior 进行限制，利用描述子配准，用边误差与一个预设的 $\\delta_c$ 比较抵消外点；\n2. 局部优化：局部 BA\n3. 回环检测：\n\t词袋模型在视觉中有很好的效果，但在 Radar 数据下并非如此，原因如下：\n\t1. 描述子重复\n\t2. 多径进一步加剧描述子的模糊\n\t3. 视觉转换导致场景剧烈变化\n\t图像转换成点云，再一次提取点，形成旋转不变描述子\n5. 优化：g2o\n文章构建基于 ORB-SLAM\n单从里程计的角度来说，并不一定[[2018 ICRA Precise Ego-Motion Estimation with Millimeter-Wave Radar under Diverse and Challenging Conditions.pdf]]好。","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/Korea/note":{"title":"note","content":"[[2020 ICRA PhaRaO_Direct_Radar_Odometry_using_Phase_Correlation.pdf]]\ntricks 结合。其中，local graph optimization 可移植到前视声呐。","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E8%A7%86%E8%A7%89%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/radar/ego-motion/University-of-Oxford/note":{"title":"note","content":"Sarah Huiyi Cen 关于雷达运动估计的文章只有两篇，目前（2022）在 MIT 做博后已转深度学习研究。\n\n采用的 FMCW 角度采样点 399，距离采样点 2000，距离分辨率 0.25米。水平方向波束宽度 2°，竖直方向波束宽度 25°，采样速率 4Hz。\n\n[[2018 ICRA Precise Ego-Motion Estimation with Millimeter-Wave Radar under Diverse and Challenging Conditions.pdf]]\n[[2019 ICRA Radar-only ego-motion estimation in difficult settings via graph matching.pdf]]\n\n两项工作分别提出、改进了利用 FMCW（frequency-modulated continuous-wave）进行自我运动估计的算法中，特征提取与特征联合的步骤。\n\n**特征提取**\n前视声呐的特征提取计划使用简单的 Harris 角点。因前视声呐分辨率相较雷达低，径向上没有明显的多径效应，故暂时先不详细了解对应的特征提取算法。\n\n**特征联合**\n2018\n\u003e it seeks to find the largest subsets of two pointclouds that share a similar shape\n\n2019\n\u003eour current method is more efficient and robust due to changes to the ***unary keypoint descriptor and termination condition***.\n\n没有关于图匹配核心算法上的区别\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6/note":{"title":"note","content":"[[2012 Calibration_and_Mosaicing_of_Forward-Scan_Sonar_DIDSON_Images.pdf]]\n无 Calibration 的内容。\n- 若 edge point，保留；否则，加权平均。然而，未说明权重的取值方式。\n\n[[2012 Detection and Tracking of Underwater Object Based on Forward-Scan Sonar.pdf]]\n提取直线检测管道。\n\n[[2012 Proceedings Ocean Sensing and Monitoring Stability augmentation and mosaic method of forward-scan sonar images.pdf]]\n开发了一种装置以增强 pan-tilt 平台的稳定性，而非一种 mosaic 算法。\n\n[[2014 IJARS An Adaptive Image-stitching Algorithm for an Underwater Monitoring System.pdf]]\n提取 SURF。数量多，匹配并运动恢复；否则，相位相关。\n\n[[2020 IET Image Processing Sonar image mosaic based on a new feature matching method.pdf]]\n说不清楚\n\n[[2021 Multimedia Tools and Applications A novel high precision mosaic method for sonar video sequence.pdf]]\n说不清楚","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/%E5%93%88%E5%B7%A5%E7%A8%8B/note":{"title":"note","content":"[[2016 OCEANS Forward-looking_sonar_image_registration_using_polar_transform.pdf]]\n\n\n[[2017 IET-RadarSonarNavi NSCT‐based fusion method for forward‐looking sonar image mosaic.pdf]]\nNSCT 变换\n\n[[2022 Sensors Journal Harbin Beam-Domain_Image_Mosaic_of_Forward-Looking_Sonar_using_Expression_Domain_Mapping_Model.pdf]]\nJOE optical flow 低配。","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Flow-based/main":{"title":"main","content":"# 光流\n\naperture problem\nAngular Error (AE) and the Endpoint Error (EPE)","lastmodified":"2023-04-18T08:00:06.195982545Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Kio-Kim/note":{"title":"note","content":"[[2004 Acoustic Camera Image Mosaicing and Super-resolution.pdf]]\nOCEANS 2004\n1. 进行预处理平衡 **insonification profile**。用高斯核平滑图像作为 **profile** 的估计，添加正则项防止低反射区域数值爆炸；\n2. 检测采用 Harris 角点，确定一个小图像 patch，在待配准图像同点周围利用 cross-correlation 暴力搜索。\n3. 融合\n\t1. SNR 最大化\n\t2. 最大似然\n\t3. **（注意，上述是递进关系。有一些先验假定，说不清楚）**\n\n[[2004 Image Mosaicing of Noisy Acoustic Camera.pdf]]\n[[2004 Image Registration and Mosaicing of Acoustic Camera Images.pdf]]\n[[2005 Mosaicing of acoustic camera images.pdf]] 该篇为 IET 的，引用最多。\n以上四篇一致（多投？）\n\n[[2005 Non-iterative Construction of Super-Resolution Image from an Acoustic Camera Video Sequence.pdf]]\n相较之前修改了图像成形的模型，增加了下采样和 PSF 的内容。但还是讲不清楚。\n\n[[2006 Video Enhancement for Underwater Exploration Using Forward Looking Sonar.pdf]]\n![[Pasted image 20221017150923.png]]\n1. Retinex Separator：高低频分离，LF 是 illumination profile，HF 是 reflectance profile （什么鬼）\n除了高低频分离，以及对 reg 的一些详细说明（一对多的配准），核心还是 MAP fusion，和之前一样。\n\n[[2008 MAP fusion method for superresolution of images with locally varying pixel quality.pdf]]\n建模成卡尔曼滤波形式，主要的贡献是在融合过程中考虑了不同位置的不确定性是不同的。","lastmodified":"2023-04-18T08:00:06.195982545Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Stevens-Institute-of-Technology/note":{"title":"note","content":"[[2020 IROS John McConnell Fusing Concurrent Orthogonal Wide-aperture Sonar Images for Dense Underwater 3D Reconstruction.pdf]]\n两个 Oculus 视角正交防止，集成于 BlueROV2。Association 仅作用于**交叉**视场。\n1. 特征提取：利用改进后的 CFAR，即 SOCA-CFAR\n2. 聚类与聚类联合：计算聚类以限定特征点的配对。聚类联合基于类别的描述子，描述子由点的均值、方差、最大最小距离构成。\n3. 特征联合：水平、竖直方向计算均值形成两个描述子\n\n所存在的问题：\n1. CFAR 适合距离检测，然而 wide-aperture 声呐的目的是探测一定的空间，而不是一个平面\n2. 交叉视场角太小，非交叉的部分没有得到利用\n3. H (Horizontal) 与 V (Vertical) 的图像之间的特征点不应该是 bijective，因为显然两者的点不是一一对应的关系，而是 m 对 n (m \u003c n) 的概率关系\n4. 聚类的部分**应该**起到主要作用的是距离（从文章所呈现的结果上来看亦是如此），其余的没有什么用，也没什么道理（尤其是方差，没有相似性）\n5. 虽然目标是复杂环境，但桥墩、防喷器都是高度对称的结构物体。\n\n***误差？***\n5m 距离下，5cm 左右的误差\n\n[[2021 ICRA John McConnell Predictive 3D Sonar Mapping of Underwater Environments via Object-specific Bayesian Inference.pdf]]\n3DOF\n\n为 2020 IROS 的拓展。2022 IROS 中提到交叉区域小，2021 ICRA 这篇在原作基础上，通过语义分类的方式对非交叉区域的进行语义分类、预测。分类通过一个手工标注的 toy-model CNN，预测通过贝叶斯。此外，加入了基于 ICP 地理近邻的回环检测。\n\n**误差？**\n等做重建的时候再关心误差\n\n[[2022 RA-L John McConnell Overhead Image Factors for Underwater Sonar-based SLAM.pdf]]\n3DOF\n\n所谓 Overhead 指的是卫星图片的分割。Factors 指的是卫星图片参与的步骤成为一个因子加入到因子图中。实操中，通过 U-Net 把当前声呐图像和 Overhead 图像合成一个当前声呐图所表示的 Overhead 图，然后与原 Overhead 图做配准获得估计。\n\n（感觉此方法非常 brittle，没有发展空间）\n\n\n[[2022 Bredan Englot Virtual Maps for Autonomous Exploration of Cluttered Underwater Enviroments.pdf]]\n注重后端，包含路径规划，建立在很多之前的工作基础上，因不太相关，留之后需要再看。\n***previous work*\n- Wang, Jinkun, and Brendan Englot. \"Autonomous exploration with expectation-maximization.\" _Robotics Research_. Springer, Cham, 2020. 759-774.\n- Wang, Jinkun, Tixiao Shan, and Brendan Englot. \"Virtual maps for autonomous exploration with pose slam.\" _2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)_. IEEE, 2019.","lastmodified":"2023-04-18T08:00:06.263982715Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Sweden/John-Folkesson/note":{"title":"note","content":"[[2022 Submit JOE Neural Shape-from-Shading for Survey-Scale Self-Consistent Bathymetry from Sidescan.pdf]]\n依赖于高精度定位信息（NOTE: iNeRF，同时估计？）\nLoss Function:\n$$\n\\mathcal{L}=\\mathcal{L}_{\\nabla}+\\alpha \\mathcal{L}_H\n$$\n其中，$\\mathcal{L}_H$ 为高度计数据与预测的差值，$\\mathcal{L}_{\\Delta}$ 则复杂一些，也重要一些：\n$$\n\\mathcal{L}_{\\nabla}=\\frac{1}{\\left|\\left\\{I_{i, n}\\right\\}\\right|} \\sum \\left\\| \\tilde{I}_{i, n}-I_{i, n} \\right\\| \n$$\n将 $\\text{ping}_i$ 的 $\\text{bin}_n$ 的点 $p_{i, n}$ 用 $\\phi_{\\text{俯仰角}}$ 参数化，得 $p_{i, n} (\\phi)$。并假设表示地面的函数在该表示下***单调***。\n\n如何求 $\\tilde{I}_{i, n}$ ？根据 Lambertion Scattering Model，需求出入射平面法向量和入射。先求曲面法向量：\n$$\nN^\\theta(p)=\\left[-\\nabla_x \\theta\\left(p_x, p_y\\right),-\\nabla_y \\theta\\left(p_x, p_y\\right), 1\\right]^T\n$$\n然后求入射角：(这一段脱裤子放屁的推导属实给我整笑了)\n$$\n\\begin{aligned}\nr_i(\\phi) \u0026= R_i R_x\\left(\\frac{\\pi}{2}\\right) R_i^T \\frac{d}{d \\phi} p_{i, n}(\\phi) \\\\ \u0026= d_n R_i R_x\\left(\\frac{\\pi}{2}\\right) \\frac{d}{d \\phi}[0, \\sin (\\phi),-\\cos (\\phi)]^T \\\\\n\u0026=d_n R_i R_x\\left(\\frac{\\pi}{2}\\right)[0, \\cos (\\phi), \\sin (\\phi)]^T \\\\\n\u0026=d_n R_i[0,-\\sin (\\phi), \\cos (\\phi)]^T\n\\end{aligned}\n$$\n直接声呐坐标减去交叉点就好了：\n$$\n\\begin{aligned}\nr_i(\\phi) \u0026= t_i - p_{i, n}(\\phi) \\\\\n\u0026=t_i - (t_i+d_n R_i[0, \\sin (\\phi),-\\cos (\\phi)]^T) \\\\\n\u0026= -d_n R_i[0, \\sin (\\phi),-\\cos (\\phi)]^T \\\\\n\u0026= d_n R_i[0, -\\sin (\\phi),\\cos (\\phi)]^T\n\\end{aligned}\n$$\n最后结合 Beam Pattern、Gain、Albedo，得到：\n$$\n\\tilde{I}_{i, n}=K A_i M_{i, n}^\\theta\\left(\\phi_{i, n}^*\\right) \\Phi\\left(\\phi_{i, n}^*\\right) R\\left(p_{i, n}\\left(\\phi_{i, n}^*\\right)\\right)\n$$\n**Experiments**\n将小于 0.3 的值，以及靠近 AUV 的一半的值舍去，以避免阴影。因为该模型只适用于有反射的情况。\n\n---\n[[2022 JOE Neural Network Normal Estimation and Bathymetry Reconstruction From Sidescan Sonar.pdf]]\n将 [[2022 Submit JOE Neural Shape-from-Shading for Survey-Scale Self-Consistent Bathymetry from Sidescan.pdf]] 中基于勃朗特反射模型的侧扫声呐回波反射预测改成又 CNN 生成。同时，SIREN 中的基于强度差的代价函数改为基于表面法向量的差的代价函数。\n\n---\n\n\n[[2022 sensors Sidescan Only Neural Bathymetry from Large-Scale Survey.pdf]]\n是\n利用 SSS 和 INR 显示测深图。\n***输入：***\n1. 反射信号的位姿（姿来自声呐、载具）和强度\n***输出：***\n1. 测深高度图\n2. 反照率图\n3. 波束形式\n4. 增益\n","lastmodified":"2023-04-18T08:00:06.263982715Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/Universidade-Federal-de-Rio-Grande/note":{"title":"note","content":"场景：partially structured scene\n\n[[2015 LARS A Topological Descriptor of Acoustic Images for Navigation and Mapping.pdf]]\n用阈值的方式找出兴趣点，扩展成高斯椭圆形成节点，暴力求解图结构的相似性。算法结果仅对 ***match*** 解释，没有里程计、回环检测等内容\n\n[[2016 OCEANS A Modified topological descriptor for forward looking sonar images.pdf]]\n通过单独分析每一 ***beam*** 自适应调整阈值，取消图配准时对 ROI 旋转角的依赖\n\n[[2016 LARS Semantic Mapping on Underwater Enviroment Using Sonar Data.pdf]]\n进一步利用算得的信息和 SVM 进行分割\n\n[[2017 ICMLA Forward Looking Sonar Scene Matching using Deep Learning.pdf]]\n\n[[2017 IFAC Description and Matching of Acoustic Images Using a Forward Looking Sonar -- A Topological Approach.pdf]]\n16 年 OCEANS 的扩展\n\n[[2018 ICMLA Underwater Place Recognition in Unknown Environments with Triplet Based Acoustic Image Retrieval.pdf]]\n深度学习的方法暴力匹配，没什么有效内容\n\n[[2018 IROS Reliable fusion of black-box estimates of underwater localization.pdf]]\n\n[[2018 JFR Underwater place recognition using forward‐looking sonarimages -- A topological approach.pdf]]\n***Important***\n1. 增强\n2. 分割\n3. 高斯椭圆拟合\n4. 图匹配\n\t1. 顶点匹配\n\t\t1. approximated solution?\n\t\t2. factorized graph match (FGM)\n\t\t3. maximum common subgraph MC strategy\n重点在于图匹配，以下为实操：\n1. 顶点匹配：用边误差小于一定值的边的个数来定义顶点的相似程度\n2. 快速图配准算法：\n\t1. 为 $v_i^1 \\in G_1$  找到两个最相似的 $v_x^2, v_y^2 \\in G_2$\n\t2. 若该两组匹配的差大于一定值，则取最大的值；反之，认为两组都不行。\n\n实验：\n1. Object Correspondence？\n2. Loop Closure Detection\n\t1. ***暴力匹配，没有快速搜索***\n\n\n[[2019 LARS 3D Surfaces Reconstruction and Volume Changes in Underwater Environments Using MSIS Sonar.pdf]]\n机械扫描声呐对超大场景的重建，注重应用（冰山观测）而非 general algorithm。","lastmodified":"2023-04-18T08:00:06.263982715Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Florence/main":{"title":"main","content":"## 2018 AUV A Forward Looking Sonar Based System for Underwater Mosaicing and Acoustic Odometry\n1. 拼图\n2. 测速\n\n### FeelHippo AUV\nFeelHippo AUV 由佛罗伦萨大学工业工程学院建造，小型、短途、浅海，用于参加面向学生的国际机器人比赛。搭载\n- U-blox 7P GPS\n- Nortek DVL1000（可充当测深仪）\n- Xsens MTi-300 AHRS，加速度计、陀螺仪、磁力计\n- KVH DSP 1760 单轴高精度光纤陀螺仪用于指北\n- EvoLogics S2CR 18/34 声学节点\n- Teledyne BlueView M900 2D FL\n- Ubiquiti PicoStation M2 高速短距宽带水面 WiFi 节点\n- Radio Modem 868+ RFDesignable 长距海面通信\n- 朝底 ELP 720p MINI 摄像头\n- Microsoft Lifecam Cinema 前视摄像头\n- 两个 ELP 1080p MINI 侧视摄像头\n- 60 厘米见方\n- 35 千克\n- 35 水深\n- 2~3 小时巡航\n- 最大航速约 1m/s\n\n### Mosaic\n前视声呐在横滚角上的变化会引起基于傅里叶域的图像配准算法退化。关于这一点，FeelHippo AUV 没有控制横滚角的推进器，维持横滚角不变的客观条件是静态水域。\n\n图像配准仅用于估计水平位移，角度估计来自 FOG。水平位移的估计与惯性导航的选择依赖于水平位移估计的尖峰与均值的比值，没有融合。\n\n~~Global Alignment 就是把相邻的两帧拼接起来。作者提到 SLAM 不适合在实时性要求较高的 AUV 上做。~~\n\nMosaic Blending 前的增强：\n1. 平均以去除 insonification pattern\n2. 利用 Contrast Limited Adaptive Histogram Equalization（CLAHE）\n3. 去除没有信息的区域\n\n### Odometry Estimation\n有什么意义？\n1. 消除 DVL 和 FLS 的串扰\n2. 深水环境下超过了 DVL 的作用距离（通常有好几十米，这个情况下 FLS 也好不到哪里去大概）\n3. 减少传感器数量\n\n### 实验\n2000 $m^2$\n![[The competion arena at the NATO STO CMRE (La Spezia, Italy).png]]\n\n\n## 2019 OCEANS Experimental Evaluation of a Forward-Looking Sonar-Based System for Acoustic Odometry\n\n在 [[#2018 AUV A Forward Looking Sonar Based System for Underwater Mosaicing and Acoustic Odometry]] 的基础上增加了以下几点分析：\n- FeelHippo AUV 增加了横向方向的速度约 0.3m/s，深度减小到 30米。\n- 建立 AUV 模型以将推力转换为速度估计\n- **利用 UKF 融合基于 AUV 模型的速度估计和 FLS 的速度估计，而不是简单的惯导与 FLS 速度估计的非此即彼的策略**\n\n### AUV 运动模型\n$$\nM \\dot{\\boldsymbol{\\nu}}+C(\\boldsymbol{\\nu}) \\boldsymbol{\\nu}+D(\\boldsymbol{\\nu}) \\boldsymbol{\\nu}+\\mathbf{g}(\\boldsymbol{\\eta})=\\boldsymbol{\\tau}(\\boldsymbol{\\nu}, \\mathbf{u})\n$$\n具体数值并不了解，但 $\\tau$ 代表了 AUV 线速度与推动器旋转角速度之间的关系。\n\n在假设海流影响较小的情况下，对 FeelHippo AUV 做了一些运动学上的假设。\n\n### FLS Registration\n增加了对所用滤波器的描述：\n在逆变换后的矩阵上应用非自适应低通巴特沃斯滤波器。\n$$\nH(u, v)=\\frac{1}{1+\\left(\\frac{D(u, v)}{D_{0}}\\right)^{2 n}}\n$$\n\n\n## 2020 OE A forward-looking SONAR and dynamic model-based AUV navigation strategy: Preliminary validation with FeelHippo AUV\n这篇文章是 2018 年 AUV 的扩展 [[#2018 AUV A Forward Looking Sonar Based System for Underwater Mosaicing and Acoustic Odometry]]，包含了 [[#2019 OCEANS Experimental Evaluation of a Forward-Looking Sonar-Based System for Acoustic Odometry]] 中的模型，但不包含滤波器。\n\n作者认为优于 DVL 的估计在近几年是不可能做到的，但与 DVL 的合作估计是可行的（但并未提到如何与 DVL 合作。\n\n[2010 JOE Autonomous Underwater Vehicle Navigation](https://ieeexplore.ieee.org/abstract/document/5546885) 提到 DVL 可能会失效：\n- 离地太近？\n- 角度太倾斜或者面临悬崖等，导致多个波束失效等\n\n文章主要注重后处理，但尽可能地模拟 online 处理的方式。\n\n进一步详细了算法步骤，新增了 FeelHippo AUV 更多的参数。\n\n平均 0.9 米，最大误差 2m。\n\n\n\n\n\n## 2020 JRF Underwater navigation with 2D forward looking SONAR: An adaptive unscented Kalman filter‐based strategy for AUVs\n这篇文章是 2019 OCEANS 的扩展 [[#2019 OCEANS Experimental Evaluation of a Forward-Looking Sonar-Based System for Acoustic Odometry]]，在 [[#2020 OE A forward-looking SONAR and dynamic model-based AUV navigation strategy Preliminary validation with FeelHippo AUV]] 的基础上加入了 [[#2019 OCEANS Experimental Evaluation of a Forward-Looking Sonar-Based System for Acoustic Odometry]] 中的滤波器。","lastmodified":"2023-04-18T08:00:06.263982715Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/University-of-Miami/note":{"title":"note","content":"# Shahriar Negahdaripour\n[[1998 OCEANS Use of Forward Scan Sonar Images for Positioning and Navigation by an AUV.pdf]]\n使用了 220KHz 的自制声呐对沉船拍了 50 张。初步使用 Optical Flow 进行位移的估计\n\n[[1998 TPAMI Revised Definition of Optical Flow.pdf]]\n\n[[2005 Epipolar Geometry of Opti-Acoustic Stereo Imaging.pdf]]\n\n[[2005 OCEANS Calibration of DIDSON Forward-Scan Acoustic.pdf]]\n利用多张已知目标物的照片来确定镜头畸变参数，从而校准 DIDSON 声呐\n\n[[2005 On Processing and Registration of Forward-Scan Acoustic Video Imagery.pdf]]\n提到[[2005 OCEANS Calibration of DIDSON Forward-Scan Acoustic.pdf]]进行预处理，纠正了beams和beams的角度畸变，通过平均图像的方法纠正声透射不均匀的问题，并沿着beams的方向取平均得到beams pattern。通过图像拼接的方式（对一个地方的成像，通过配准校正重叠）评估噪声，得到bimodel噪声。讨论conformal和affine变换对声呐图像变换来说是合理的近似。利用手动提取配准特征解conformal模型以及自动提取配准特征解仿射变换模型比对拼图结果，并认为投影变换参数较多，而匹配特征较少，所以结果不稳定。\n\n[[2007 3D Motion from 2-D FLS Video.pdf]]\n运用 Harris 角点和 Lucas-Kanade 追踪匹配点，求解 9 自由度 Homography Matrix。无详细数据分析和过程。\n\n[[2010 OCEANS 3-D Motion Estimation in passive navigation by acoustic imaging.pdf]]\n没有提什么是 passive navigation。将 arc 分为 low、medium、high 三个区域。没有提到如何建立特征点的 match，利用 hough array 估计角度、平移，并有一些评价指标，如角度估计倾向于两个特征点为沿着声呐横向移动的方向。角度估计误差约 1.5 °，距离约厘米至10厘米级。提及该工作可以为双声呐的点对关系打下基础。\n\n[[2010 OCEANS On 3-D reconstruction from stereo FS sonar imaging.pdf]]\n相较于 2009 年第一篇 Herriot Watt 的垂直方向上叠放的双声呐系统，这篇文章解决任意摆放（非严格对准）情况下的声呐双目视觉，并分析退化问题。文章假设该任意摆放的位置是可以通过配准标定的，已知的。\n\n[[2010 OCEANS Performance and accuracy in visual motion computation from FS sonar video sequences.pdf]]\n主要为误差分析。仍然没有自动的特征点提取配准\n\n[[2011 OCEANS Dynamic scene analysis and mosaicing of benthic habitats by fs sonar imaging-issues and complexities.pdf]]\n提出动态环境下声呐图像配准、拼接等问题，包含特征点选取、跟踪、融合图像处理等\n\n[[2012 CVIU Visual motion ambiguities of a plane in 2-D FS sonar motion sequences.pdf]]\n\n---\n[[2012 OCEANS On feature extraction and region matching for forward scan sonar imaging.pdf]]\n[[2013 JFR On feature matching and image registration for two‐dimensional forward‐scan sonar imaging.pdf]]\n相比 [[2010 IROS Johannsson.pdf]] 可以多估计声呐的俯仰，直接采用 3D 声呐运动模型，采用 Gaussian Map 而不是 NDT Map（NDT map 需要选择方格大小，从而平衡了精度和计算时间）\n特征点的检测基于强度的信息，总觉得处理起来不是那么方便。\n利用 object-shadow pair 计算 occluding contour 的三维点，该三维点至起始点位之间的俯仰角用线性插值补齐（没有利用亮度区域的强度值）\n\n仅利用\n$$\n\\mathbf{s}^{\\prime}=H \\mathbf{s}, \\quad H=\\left[\\begin{array}{ccc}\n\\left(1-\\frac{t_{z} \\sin \\phi}{R}\\right) \u0026 \\omega_{z} \u0026 -\\frac{t_{x}}{\\cos \\phi} \\\\\n-\\omega_{z} \u0026 \\left(1-\\frac{t_{z} \\sin \\phi}{R}\\right) \u0026 -\\frac{t_{y}}{\\cos \\phi}\n\\end{array}\\right]\n$$\n进行分析有这么五个量有影响，然后计算出 $\\phi$ 后，就可以换成普通的 $\\vec{t}$  进行优化了。\n但 $R$ 应该是受约束的，文中却说 Matlab 求解时没有约束。\n\n---\n1. [[2012 OCEANS On 3-D Motion estimation from 2-D sonar image flow.pdf]]\n2. [[2012 OCEANS On 3-D Scene Interpretation from F-S Sonar.pdf]]\n3. [[2013 OCEANS Forward-look 2-D sonar image formation and 3-D reconstruction.pdf]]\n4. [[2013 T-RO On 3-D motion estimation from feature tracks in 2-D FS sonar video.pdf]]\n\n1 中介绍 image flow 的微分\n\n2 中介绍如何利用高度计、斜度计辅助判断每一个特征点的**俯仰角，以及所在平面（平面假设）的法向量**。并利用 radiometric 方向上 object-shadow 辨识，提取 object-shadow 轮廓，估计\n物体轮廓。但表述并不清楚，且轮廓提取、特征点提取没有对应的方法介绍。\n\n3 同时测试了在水中的物体（鱼类）以及置底的物体。假设物体在声呐坐标系中**距离单调变化**。虽然考虑了两片 patches 同时反射声波的情况，但考虑得较为简单粗暴。也考虑了地面反射抵达物体表面从而生成的回波，该回波被简单（人工）去除。方法为：根据 object-shadow 得到物体的起始、结束三维点，从底开始连续地根据回波强度计算物体表面至顶部。\n\n---\n[[2015 OCEANS Modeling 2-D forward-scan sonar imagery for diffuse reflectors.pdf]]\n[[2016 JOE Modeling 2-D lens-based forward-scan sonar imagery for targets with diffuse reflectance.pdf]]\n\n---\nspace carving\n[[2015 OCEANS Modeling 2-D forward-scan sonar imagery for diffuse reflectors.pdf]]\n[[2017 JOE Space Carving.pdf]]\n[[2017 OCEANS Refining 3-D object models constructed from multiple FS sonar images by space carving.pdf]]\n\n---\n双目\n[[2018 OCEANS Analyzing epipolar geometry of 2-D forward-scan sonar stereo for matching and 3-D reconstruction.pdf]]\n[[2020 JOE Application of forward-scan sonar stereo for 3-D scene reconstruction.pdf]]","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/calibration":{"title":"calibration","content":"# 一些资源汇总\n- https://github.com/SoundMetrics/aris-file-sdk/tree/master/beam-width-metrics 中有官方给出的 ARIS 声呐的 beam pattern 的数据。 \n- https://github.com/pvazteixeira/multibeam 给出了处理 DIDSON mapping 的方法。给出的 DIDSON 的 fov 是 *0.5026548245743669/28.8*，根据表格计算出的是 *28.812*。fov 在更新 azimuth 的过程中**还是赋值成了 *28.812***。每次更新 azimuth 后，需要用 5 阶的曲线拟合 azimuth table。在计算 lookUpTable 时需注意， res 应该是一个合理的值。在 pivazteixeira 的计算中很有可能是一个极小的值，甚至可能是 0（当 rmin = 0 时）。其中，coefficients 的计算与 Matlab 相同。\n- http://www.soundmetrics.com/My-Account/Downloads/DIDSON/Products/DIDSON-300m/DIDSON-300m-Product-Specs-English.pdf 官方给出的 DIDSON fov 为 29°\n- 官方的邮件回复中告知 ARIS 的 beam width 是由多个 lens 的平均组成，标定是 27.8°。官方的 GitHub 文件中若按 beam's center 计算则是 27.625°，按照最左侧至最右侧计算为 27.839°。\n- 官方提到 lens 的硬件上，DIDSON 与 ARIS 是一样的，只是官方的软件在处理 DIDSON 时用的是 curve fit，在处理 ARIS 时为 table。\n- 2005 OCEANS Calibration 中给出的官方数值为：\n$$\ns(a_3\\theta ^3+a_2\\theta ^2 + a_1\\theta + a_0)\n$$\n其中，$s=1.012$, $a_3 = 0.0030$, $a_2=-0.0056$, $a_1=2.7151$, $a_0=48.62$.\n- 2020 年更新的 DIDSON Matlab 脚本中数值为：\n$s=1.012$, $a_3 = 0.0030$, $a_2=-0.0055$, $a_1=2.6829$, $a_0=48.04$.\n- \n# 如何写一个好的 mapping function？\n## 一些注意事项\n1. 对于 ARIS 声呐，拿到的是 `BeamLookUpTable`，对于 DIDSON，pvazteixeira 既给出了 table，也可从 Matlab 一样的系数进行计算。\n2. 图的分辨率应可任意选择，默认高度与 polar 图像的 bin 的个数一致。\n3. 图上的每一个像素点会产生一个角度，当为系数时，角度可以方便地转换成 BeamNum；当为 `BeamLookUpTable` 时，既可以通过拟合曲线再计算 BeamNum，也可以通过 BeamWidth 直接归到某一个 BeamNum 里。不过曲线拟合的方式可以更简单地进行线性插值。\n## 具体步骤\n```\nmeters_per_bin = (maxr - minr) / num_bins\nmeters_per_pixel = 0.01\nres = meters_per_pixel\n\nwidth_in_meters = maxr*(sin(maxa) - sin(mina))\nwidth_in_pixels = ceil(width_in_meters / meters_per_pixel)\nxres = width_in_meters / width_in_pixels\nx0 = \n\nheight_in_meters = maxr - minr * cos(min(abs(maxa) abs(mina)))\nheight_in_pixels = ceil(height_in_meters / meters_per_pixel)\nyres = height_in_meters / height_in_pixels\ny0 = \n\n# res / xres / yres 有微小的差别。res 越小，差别也应越小。\n\n# 创建\n(mag, angle) = cv2.cartToPolar(x.flatten(), y.flatten())\n\nrow_polar = mag\ncol_polar = angle\n```\n\n\n---\n\n[[2005 OCEANS Calibration of DIDSON Forward-Scan Acoustic.pdf]]\n做一个方框\n![[Pasted image 20221028103203.png]]\n假设完上面每一个点的坐标，则可通过外参（至相机坐标系）、映射（包含内参的 3D -\u003e 2D 过程）得到两个测量。目前主要是对 Beams 进行矫正，一个点为一次测量，但有 4 个未知量。假设一次观测中有 K 个点，则有 K 个测量，未知量为 6 + 4，则需要 $K \\ge 10$ 才能解出三次多项式的 4 个未知数。在这个过程中，图像中的点（提取、位置确定）与方框实物上的点的匹配关系是已知的。\n\n**可能存在的问题**\n1. 由于量化误差的存在，可能点越近越集中，数值计算越不稳定（可从矩阵条件数推断）。\n2. 三次多项式不一定好。\n3. 交替推断的方式的收敛不一定是最优。\n\n**提出一个新的方法可以具有的优点**\n1. 不需要标定物，只需要海底一些特征等\n2. 不依赖于三次多项式\n3. jointly optimization\n\n# 采用直线信息进行校准\n## 相关工作\n1. 上海大学 [[2012 Detection and Tracking of Underwater Object Based on Forward-Scan Sonar.pdf]]\n2. 上海大学，类似的共两篇，都发在 AOR 上[[上海大学/2021 Applied Ocean Research A submarine pipeline segmentation method for noisy forward-looking sonar.pdf]]\n3. [[2021 JOE 泰国 A_Pipeline_Extraction_Algorithm_for_Forward-Looking_Sonar_Images_Using_the_Self-Organizing_Map.pdf]]\n\t1. CFAR \n\t2. 先扩张后消除小片区域以提取连接的管道（hyperparameters多得离谱）\n\t3. 利用 Self-Organizing Map 用一维分段直线去拟合二维管道（应有一定的必要性）\n4. 2022 OCEANS Hampton Roads --- Real-time Wall Identification for Underwater Mapping using Imaging Sonar。用了 MSIS 和 Hough Transform 检测墙等平面（所形成的直线）\n5. \n\n## 相关公式推导\n## 基础的变换公式\n### 直角坐标系至极坐标系\n$$\n\\mathbf{p}=\\left[\\begin{array}{l}\nx \\\\\ny \\\\\nz\n\\end{array}\\right]=\\left[\\begin{array}{c}\nr \\cos \\theta \\cos \\phi \\\\\nr \\sin \\theta \\cos \\phi \\\\\nr \\sin \\phi\n\\end{array}\\right]\n$$\n### 极坐标系至直角坐标系\n$$\n\\mathbf{s}=\\left[\\begin{array}{l}\nr \\\\\n\\theta \\\\\n\\phi\n\\end{array}\\right]=\n\\left[\\begin{array}{c}\n\\sqrt{x^2+y^2+z^2} \\\\\n\\arctan 2(y, x) \\\\\n\\arctan 2\\left(z, \\sqrt{x^2+y^2}\\right)\n\\end{array}\\right]\n$$\n### 波束的表示\n假设共有波束$N$个，第$n$个波束的开角为：\n$$\\theta_n, n\\in \\{1, 2, 3,...,N\\}$$\n同时，用：\n$$\n\\theta_{n, n+1}, n\\in\\{1, 2, 3,...,N-1\\}\n$$\n表示$\\theta_n$与$\\theta_{n+1}$之间的距离（弧度）。\n\n## 假设直线处于投影平面\n则直线上处处 $\\phi=0$。\n\n进一步假设直线贯穿声呐视角，我们会得到这样的一组数据：\n$$\n\\mathbf{p}_l = \\{\\theta_{n},r_{n}\\},n\\in \\{1, 2, 3,...,N\\},\n$$\n其中，$r$来自于**真实的**$\\theta$的采样，$\\mathbf{p}_l$为表达直线的一组点。这组点在直角坐标系下呈现**非均匀采样**。假设一条直线为：\n$$\nax+by+cz=d,\n$$\n通过转换公式可以得：\n$$\na(r \\cos \\theta \\cos \\phi)+b(r \\cos\\phi \\sin\\theta)+c(r\\sin\\phi)=d.\n$$\n由于$\\phi=0$，则简化为：\n$$\na(r \\cos \\theta)+b(r\\sin\\theta)=d.\n$$\n根据$N$个测量点，得到：\n$$\n\\left[\n\\begin{array}{c}\nr_1\\cos\\theta_{1} \u0026 r_1\\sin\\theta_{1} \u0026 -1 \\\\\nr_2\\cos\\theta_{2} \u0026 r_2\\sin\\theta_{2} \u0026 -1 \\\\\n... \u0026 ... \u0026 ...\\\\\nr_N\\cos\\theta_{N} \u0026 r_N\\sin\\theta_{N} \u0026 -1 \\\\\n\\end{array}\n\\right]\n\\left[\n\\begin{array}{c}\na \\\\\nb \\\\\nd\n\\end{array}\n\\right]\n\n=\n\n\\mathbf{0}^{N \\times 1}\n,\n$$\n形式为：\n$$\n\\mathbf{Ax } = \\mathbf{0}\n$$\n$\\mathbf{A}^T\\mathbf{A}$最小特征值对应的特征向量即为解，即求得直线方程。求得直线方程后可求得每一个$\\theta$所映射的点与直线的距离（沿弧线）：\n$$\n\\mathcal{L}_i = \\mathop{\\arg\\min}_{\\theta_{\\text{new}\\in\\{\\theta_{\\text{new1}}, \\theta_{\\text{new2}}\\}}} (\\theta_{\\text{new}} - \\theta_{\\text{old}}),\n$$\n$$\n\\{\\theta_{\\text{new1}}, \\theta_{\\text{new2}}\\} = \\arcsin(\\frac{2bp\\pm\\sqrt{4a^2(a^2+b^2-p^2)}}{2(a^2+b^2)}),\n$$\n$$\np = \\frac{d-cr\\sin(\\phi)}{r\\cos(\\phi)}.\n$$\n$\\mathcal{L}$的下标表示第几条直线。最终\n$$\n\\mathcal{L} = \\frac{1}{N_{\\text{L}}}\\sum^{N_{\\text{L}}}_{i=1}\\mathcal{L}_i\n$$\n实操发现一轮更新即陷入局点。故改为优化直线方程参数。\n\n设直线$L_i, i\\in\\{1, 2, ..., N_{\\text{L}} \\}$的参数为$a_i, b_i, c_i, d_i$，其对应的距离采样为 $\\mathbf{r}_i$，则对应的角度为：\n$$\n\\sin{\\mathbf{\\theta}_i} = \\min(\\frac{2b_ip_i\\pm\\sqrt{4a_i^2(a_i^2+b_i^2-p_i^2)}}{2(a_i^2+b_i^2)}).\n$$\n由于通常$-\\frac{\\pi}{2} \u003c \\theta \u003c \\frac{\\pi}{2}$，故用$\\sin{\\theta}$代替$\\theta$可行。因为同一款声呐的$\\theta$一致，则有：\n$$\n\\mathcal{L} =\\mathop{\\arg\\min}_{a_1, b_1,c_1,d_1,...,a_{N_\\text{L}}, b_{N_\\text{L}},c_{N_\\text{L}},d_{N_\\text{L}}}\n\\sum_{i=1}^{N_\\text{L}} (\\sin\\theta_i - \\mu)^2.\n$$\n其中，$\\mu = \\frac{1}{N_\\text{L}}\\sum_{i=1}^{N_\\text{L}}\\sin\\theta_i$ 。\n\n\n\n\n","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/detection":{"title":"detection","content":"# Paper List: 与声呐相关的目标/纹理/显著检测\n*不仅仅是多波束前视声呐，也包含侧扫、合成孔径等*\n\n[[1984 JASA T.K. Stanton Sonar Estimates of Seafloor Microroughness.pdf]]\n\n[[2002 Ronald Kessel Using Sonar Speckle to Identify Regions of Interest and for Mine Detection.pdf]]\n\n[[2003 Ronald Kessel Texture-based Discrimination of man-made and natural objects in sidescan sonar imagery.pdf]]\n\n[[2003 JOE An Automatic Approach to the Detection and Extraction of Mine Features in Sidescan Sonar.pdf]]\n***利用 MRF 分割阴影、背景、目标***。利用了被检测物体在声呐图像中的大小的先验信息。\n\n[[2007 JOE Mean–Standard Deviation Representation of Sonar Images for Echo Detection - Application to SAS Images.pdf]]\n利用 Mean-Standard Deviation 表示法计算一二阶统计特性来代替传统的基于强度的阈值方法来检测 SAS 中的水下目标。\n但 Mean-Standard Deviation Plane 失去了图像的空间信息 \n\n[[2011 ICIRS David P. Williams On Adaptive Underwater Object Detection.pdf]]\n这篇文章又简单又复杂。服了。\nhighlight-shadow pattern recognition 是过去水下目标检测的重要手段，缺有以下几点问题：\n1. 检测算法任务图像质量是均匀的\n2. 未考虑目标物回波和阴影的距离依赖性（物理传播模型可补偿）\n3. 没有考虑到执行任务时的地理环境，而采用了来自不同环境的训练图片\n4. 检测阈值与物理意义无关，是一个经验值\n5. 采用 ..... （不知道您在说什么）\n文章的算法由三个部分组成：\n1. shadow detection\n\t1. 采用 integral-image 表示\n\t2. 估计背景。Background Score 就是该像素点周围的均值。\n\t3. 估计阴影。已知 AUV 高度\n2. ripples detection\n3. object echo detection\n\n\n[[2012 OCEANS Integrated MCM missions using heterogeneous fleets of AUVs.pdf]]\n文章更多描述了一个系统。系统中包含了 SAS、SSS、FLS 的 ATR 效果。\n\n \n注重 man-made objects。**但方法部分没有讲 man-made 特殊在哪。**\n并非整个图像，而只关注手动选取的 ROI。计算背景时排除滑动窗口内的像素，计算回声时只计算滑动窗口内的元素。\n![[Pasted image 20220726215903.png]]\n\n---\n[[2014 Ferreira Improving Automatic Target Recognition with Forward Looking Sonar Mosaics.pdf]]\n[[2015 Ferreira Forward looking sonar mosaicing for Mine Countermeasures.pdf]]\n应用声呐拼接图像提高信噪比，提升 MCM 的成功率。\n避免从各个角度照射物体，比如 parallel and perpendicular 来造两个图\n\n![Pasted image 20220726215903.png](https://cdn.jsdelivr.net/gh/HikariS97/gallery@main/Pasted%20image%2020220726215903.png)\n\n\n同样避免 loop closure 以防止离谱的优化\n采用 DGPS/INS 与 Correlation 结合的方式\n提出简单的融合方法，利用新的图片和过去 mosaic 的平均。同样无法避免目标信息被地面反射淹没的问题。\n有明显的缝隙\n\n---\n\n[[2015 GRSS David P. Williams Fast Unsupervised Seafloor Characterization in Sonar Imagery Using Lacunarity.pdf]]\nSupervised 有其固有的缺陷：1. 遇到新地形时；2. 水下地形往往是复杂的复合，而很少能简单的区分。利用 Lacunarity 计算图片以区分地形，采用 ***integral image*** 加速。\n\n---\n[[2020 JASA 中科院 Detecting moving targets in active sonar echograph of harbor environment using high-order time lacunarity.pdf]]\n将 Lacunarity 拓展到时间维度，并增加了阶数。\n当所截取的时间窗口无穷大时，方差趋近于无穷小（假设大部分时间是静止的），则 $Lac$ 趋近无穷小，无法区分 ***Target***。因此，对时间窗口的选择是一个需要考虑的问题。\n\n***Lacunarity*** 由 Mandelbrot（1983）于分形几何中提出，并由 Plotnick（1996）扩展至可以对灰度图像的像素点变化进行评估。\n关于 ***Lac*** 的计算：\n$$\nL=E\\left[\\left(\\frac{P_{t}}{E\\left[P_{t}\\right]}-1\\right)^{2}\\right]\n$$\n当 $P_t$ 越偏离期望值，则 $L$ 的值越大。\n\n---\n[[2022 JOE Narcís Palomeras Automatic_Target_Recognition_for_Mine_Countermeasure_Missions_Using_Forward-Looking_Sonar_Data.pdf]]\n利用神经网络自动检测目标物\n\n[[2022 JOE Validation of Targets in Sonar Imagery Using Multispectral Analysis.pdf]]\ntodo...\n\n\n\n# Paper List: 图像融合相关\n[[2004 OCEANS Fusion of Multiple Side-scan Sonar Views.pdf]]\n利用 Gabor Wavelet Decomposition 分离空间频率，进行融合，最后再合成频率，获得最终的侧扫图像拼接。\n\n[[2006 TIP The Fusion of Large Scale Classified Side-Scan Sonar Image Mosaics.pdf]]\n\n\n[[2012 David P. Williams SAS and Bathymetric Data Fusion for Improved Target Classification.pdf]]\n将一个物体不同视角的 SAS 图像融合成单张多视角 SAS 图像。\n但文中使用的示例并没有解决目标被背景平滑的问题，而是像右子图所示的那样尽可能使其重合。基于特征点、区域、模板的方法均不适用于 SAS 图像（提到了基于已知物体的投影，但 Yusheng Wang 2022 OCEANS 并未引用），故提出了利用额外的信息源：Bathymetry Map 来恢复物体的高度。并且只假设了位移的存在，并没有考虑到旋转的因素。（手动旋转）\n![[detection1.png]]![image](./Attachments/detection1.png)\n\n[[2013 OCEANS Hurtos A novel blending technique for two-dimensional forward-looking sonar mosaicing.pdf]]\n有两种图像融合的技术类别：1. 柔和边缘，2. seam finding 来寻找合适的切割线\n提到了无用的信息会 fading out 有用的信息，但只考虑了精准配准的情况，没有考虑到不精准回环时将有用信息中和的是海底背景，无法通过 saliency map 去除。\n\n[[2015 Ferreira Real-time mosaicing of large scale areas with forward looking sonar.pdf]]\n利用 DGPS 或 USBL 的信息得到已拼接图像与新图像的相关关系。不知道具体怎么做的，反正也没啥大用。\n\n[[2018 IROS Pedro V. Teixeira Multibeam Data Processing for Underwater Mapping.pdf]]\n算法的特殊之处：1. 窄波束宽度，2. 探测悬浮空中物体。\nNOTE: Related Work 可以做很多参考\n做了预处理，使分割的结果更加准确。\n分割的效果依赖于先验分布\n\n[[2020 Gloabl Oceans Jose Melo A Belief Propagation based algorithm for autonomous mapping of underwater targets.pdf]]\n运用复杂的 BP 方法（似乎是近年才提出的），整合了一个目标物多次 Detection 的信息。\n\n\n# 图像分割 Review\n## 概率图模型 Review\n# Roadmap\n## 目的\n\n\n**2D 多波束前视声呐**相较于**侧扫声呐**具有更多波束，相较于**多波束回声测深仪**具有更大的波束宽度，一次成像时对更大的体积空间进行声探测，是潜器近底自主导航的基础。相较于**机械扫描式声呐**成像帧率较高，不易受到潜器自身运动的影响。相较于 **3D 多波束前视声呐**，**合成孔径声呐**，**水下激光雷达** 价格较低，体积较小。相较于**光学探测设备，如：摄像头** 不易受到水体浑浊程度的影响。高频 2D FLS 具有厘米级的近距离观测精度，是现代化探测的重要设备。\n\n其成像原理虽然已经得到了很好的几何分析，但由于传感器信噪比相对较低，声波作用于物体表面时的散射建模较为复杂，且海底感兴趣物体的尺寸通常较小，成像效果受到 vintage point 的巨大影响等因素的影响，2D FLS 的成像分析仍然不够精准。这个不精准直接导致了精准的物体重建和目标检测领域的重要挑战，目前仍然是研究的热点。\n\n尽管如此，仍然有很多先前的工作意在利用 2D FLS 处理 low level 的视觉问题，如：自我运动估计[........]、图像拼接[......]、三维重建[........]。其中，2012年 Girona 的工作因其引入了傅里叶变换而获得了稳定的帧间估计，以及引入 Pose Graph 进行全局平滑处理，生成了极其振奋人心的高清声学图像拼接结果，而备受关注。其中，回环检测对高精度图像的生成起到了巨大的作用。我们知道，回环检测在[.....]得到了广泛应用，其可以通过平滑的方式 bound error。在探测巡航任务中，为了确保覆盖待探测区域，潜器往往回覆盖式地进行走航式任务，导致图像和图像之间（非时间上相邻，而是条带相邻）具有较大的重合。这个重合是回环检测的基础之一。如 Girona 所示的那样，如果没有回环检测，由于帧间配准的累积误差，图像会变得模糊。而有了回环检测，图像会清晰很多。我们发现由于声呐图像受 vintage point 的影响较大，Girona 的工作中声呐的 膛线瞄准方向 垂直于潜器行进方向，且利用了潜器可以左右平移的特点使得声穿透始终来自一个（大致）的方向，使得不同条带的图像具有相似的成像效果，这是回环检测的基础之二。而普通 AUV 往往不具备这样的能力，但 浙大的 AUH 和 [....] 具备，或者利用电机，如 SoundMetrics 官方就有提供的 AR2/AR3，也可做到类似结果。然而，前视声呐如其名字所阐释的那样，对 forward saliency detection 有着重要的意义。2018 Florence 虽然将声呐配置调整为前向，但其并没有使用回环检测，也可以在拼接结果中看到救生浮筒的光影反映出了 vintage point 的不同。2019 JFR 基于相对位置进行回环检测，但所使用的数据集与常见的回环图像不类似，.......。因此，回环检测是一个还未较好解决的问题。因此，如 Girona 所示的那样清晰的图像也许适用于小范围可控环境的拼接图像生成，而并不适用于实际的大范围未知环境的扫测任务。\n\n巡航任务中，目标检测往往是终极目标，如：海底管道跟踪、反雷工作等 [..............]。2022 年 JOE 的反雷工作是目前可知的最新的反雷工作，工作区域小，利用了神经网络。Debris 那片论文提供了数据集，但相比于传统 CV 界，数据量很小。且如上述，图像模态受到大量因素影响。因此，基于数据驱动的方法还需要大量的数据去补充。虽然有很多模拟器出现，但其往往只考虑了几何成像原理，导致生成结果和实际图像有较大的隔阂。Yusheng Wang 有 CycleGAN 进行模态生成，但......。2022 年 Naval 那一片考虑了物理，但受限于声呐的物理性质，大规模生成图像仍然较早。传统的方法由于较小的分辨率往往容易失效。\n\n为了使 Correlation 的方法更加鲁棒，我们采取更高的帧率。但大量的图片会影响拼接结果。\n\n声学图像拼接可以将几百上千张图像拼接为完整的大图，是扫测区域的一种更紧凑的表达方式。一张清新的地图可以方便人眼快速找出感兴趣位置，定位可疑目标物位置。然而，主要有两类误差使得获得清晰的可见的声学地形图较为困难：\n1. imaging pattern. \n\t1. ARIS 和 Blueview 似乎可以调节到底部的距离，但 Oculus 无法调节距离。这一距离需要结合声呐俯仰角度和高度计才能撇去，在没有高度计的情况下需要估计黑色的部分。这虽然较为麻烦，但也可以去除，哪怕精度不是很高。如 Oculus 声呐的一个 pattern，会加大去除的复杂程度。（2014 Blending 中也有使用）\n\t2. 远距离截止点。容易受到多径和旁瓣的影响，甚至不一定呈现黑色区域，导致目标物进入视野的时候不一定出现在图像边缘处。\n2. accmulated error.\n\t1. 在来回扫测时同一个物体出现在不同的全局坐标位置，因此，本应该出现两处的目标被背景反射平均，导致不明显甚至消失。\n\n有不少的方法尝试建立 3D 模型，可以一定程度上将目标物分离出物体。但其复杂的几何逻辑和假设，以及在面对复杂物体时，3维重建往往丢失了很多细节，与人眼清晰可见的目的背道而驰。\n\n2014/2015 Ferreira 利用图像拼接进行反雷，但没有考虑以上的细节，仅仅使用拼接增强图像质量，再输入 ATR 算法。\n\n因此，文章的目的就是在上述两个图像融合的误差下，使得目标物体清晰可见。\n\n\n我们需要提出几个问题：\n1. 假设已经拿到每一张图像中目标物完美分割的轮廓，如何设定 Blending Method 才能较好得突出目标物显示？\n2. 如何获得图像中目标物的分割轮廓？这是一个分割问题，需要把图像分割成前景、背景，或者目标、阴影、背景。\n\t1. 利用 SpatioTempo Lacunartiy 为什么不行？\n\n\n# 相关软件\n[SAMM](https://www.oicinc.com/samm.html)\nOceanic Imaging Consultants\n支持众多声呐，但拼接基于 GPS 数据\n\n[ClearSight](https://acousticview.com/)\nAcousticView\n只支持 Didson，上限 1000 frames。\n\n[SoundTiles](https://iquarobotics.com/soundtiles)\nIQUA Robotics\n支持众多声呐\n\n都没有明显地考虑到外场实验的配置\n\n\nLBL/USBL 设备以及其自身的标定工作都是相对于探测设备的额外成本","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/odo":{"title":"odo","content":"# 2D 前视声呐里程计估计\n\n## 相关工作\n\n### MIT \u0026 CMU\n[[2010 IROS Johannsson.pdf]]\n[[2012 IJRR ShipHull.pdf | 2012 IJRR ShipHull]]\n结合阴影聚类点块，利用 NDT 方法避免特征的匹配。用了 Pose Graph 但没有写如何获得配准的误差估计，也没有写如何利用传感器信息获取得到 loop closure。（有可能是通过估计的位置搜索半径）\n### Girona\nGirona 的方法主要基于傅里叶域，其核心可总结为 2015 年发表于 JFR 的文章：[[2015 JFR.pdf]]。\n对于变换矩阵，其选择了近似成二维欧式变换的 $\\mathbf{H}$.\n想象一个球面，$P$ 为水平面、球面上的一点。由于前视声呐通常以一个较小的掠射角进行装载，因此成像平面为一个斜切面。当该斜切面绕球体的 z 轴旋转时，点 $P$ 沿圆周投影至斜切面，距离与圆心保持不变；与投影平面的 $\\phi$ 发生变化，会导致成像强度变化；方位角 $\\theta$ 不变。\n\n综上，$\\theta$ 得到了保持；平移受俯仰角影响会得到压缩，若 $\\phi$ 恒定则得到稳定的压缩。因此，可以近似成一个二维欧式变换。\n\n## 拟采用方法\n1. 原始图像经过中值滤波；\n2. 提取 CFAR 特征点；\n3. 利用 CPD 获得估计，同时获得点对之前的匹配关系；\n4. \n\n## 需对比的方法\n1. ICP\n2. 复现 NDT\n3. Fourier-based","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/FLS%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86/some-math/Speckle-Noise-Related-Statistics":{"title":"Speckle Noise Related Statistics","content":"Weibull Distribution\nGamma Function\nRayleigh Distribution\n","lastmodified":"2023-04-18T08:00:06.279982754Z","tags":[]},"/Research/Pasted-image-20220726215903.png":{"title":"Pasted image 20220726215903.png","content":"","lastmodified":"2023-04-18T08:00:06.187982526Z","tags":[]},"/notes/CJK-+-Latex-Support-%E6%B5%8B%E8%AF%95":{"title":"CJK + Latex Support (测试)","content":"\n## Chinese, Japanese, Korean Support\n几乎在我们意识到之前，我们已经离开了地面。\n\n우리가 그것을 알기도 전에 우리는 땅을 떠났습니다.\n\n私たちがそれを知るほぼ前に、私たちは地面を離れていました。\n\n## Latex\n\nBlock math works with two dollar signs `$$...$$`\n\n$$f(x) = \\int_{-\\infty}^\\infty\n    f\\hat(\\xi),e^{2 \\pi i \\xi x}\n    \\,d\\xi$$\n\t\nInline math also works with single dollar signs `$...$`. For example, Euler's identity but inline: $e^{i\\pi} = -1$\n\nAligned equations work quite well:\n\n$$\n\\begin{aligned}\na \u0026= b + c \\\\ \u0026= e + f \\\\\n\\end{aligned}\n$$\n\nAnd matrices\n\n$$\n\\begin{bmatrix}\n1 \u0026 2 \u0026 3 \\\\\na \u0026 b \u0026 c\n\\end{bmatrix}\n$$\n\n## RTL\nMore information on configuring RTL languages like Arabic in the [config](notes/config.md) page.\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/Editing+and+formatting/Callouts).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"🪴 Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'مدونتي'\n    weight = 1\n```\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":["setup"]},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/notes/docker":{"title":"Hosting with Docker","content":"\nIf you want to host Quartz on a machine without using a webpage hosting service, it may be easier to [install Docker Compose](https://docs.docker.com/compose/install/) and follow the instructions below than to [install Quartz's dependencies manually](notes/preview%20changes.md).\n## Hosting Quartz Locally\nYou can serve Quartz locally at `http://localhost:1313` with the following script, replacing `/path/to/quartz` with the \nactual path to your Quartz folder.\n\ndocker-compose.yml\n```\nservices:\n  quartz-hugo:\n    image: ghcr.io/jackyzha0/quartz:hugo\n    container_name: quartz-hugo\n    volumes:\n      - /path/to/quartz:/quartz\n    ports:\n      - 1313:1313\n\n    # optional\n    environment:\n      - HUGO_BIND=0.0.0.0\n      - HUGO_BASEURL=http://localhost\n      - HUGO_PORT=1313\n      - HUGO_APPENDPORT=true\n      - HUGO_LIVERELOADPORT=-1\n```\n\nThen run with: `docker-compose up -d` in the same directory as your `docker-compose.yml` file.\n\nWhile the container is running, you can update the `quartz` fork with: `docker exec -it quartz-hugo make update`.\n\n## Exposing Your Container to the Internet\n\n### To Your Public IP Address with Port Forwarding (insecure)\n\nAssuming you are already familiar with [port forwarding](https://en.wikipedia.org/wiki/Port_forwarding) and [setting it up with your router model](https://portforward.com):\n\n1. You should set the environment variable `HUGO_BASEURL=http://your-public-ip` and then start your container.\n2. Set up port forwarding on your router from port `p` to `your-local-ip:1313`.\n3. You should now be able to access Quartz from outside your local network at `http://your-public-ip:p`.\n\nHowever, your HTTP connection will be unencrypted and **this method is not secure**.\n\n### To a Domain using Cloudflare Proxy\n\n1. Port forward 443 (HTTPS) from your machine.\n2. Buy a custom domain (say, `your-domain.com`) from [Cloudflare](https://www.cloudflare.com/products/registrar/). Point a DNS A record from `your-domain.com` to your public IP address and enable the proxy.\n3. Set the environment variables `HUGO_BASEURL=https://your-domain.com`, `HUGO_PORT=443`, and `HUGO_APPENDPORT=false`. Change `1313:1313` to `443:443` for the `ports` in `docker-compose.yml`.\n4. Spin up your Quartz container and enjoy it at `https://your-domain.com`!\n\n### To a Domain using a Reverse Proxy\n\nIf you want to serve more than just Quartz to the internet on this machine (or don't want to use the Cloudflare registrar and proxy), you should follow the steps in the section above (as appropriate) and also set up a reverse proxy, like [Traefik](https://doc.traefik.io/traefik). Be sure to configure your TLS certificates too!\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":["setup"]},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so, otherwise the generated page will not have a title!\n\nYou can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e 🔗 Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":["setup"]},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions Permissions\nBy default, GitHub disables workflows from modifying your files (for good reason!). However, Quartz needs this to write the actual site files back to GitHub.\n\nHead to `Settings \u003e Action \u003e General \u003e Workflow Permissions` and choose `Read and Write Permissions`\n\n![[notes/images/github-actions.png]]\n*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/notes/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\n❌ [Excluding pages from being published](notes/ignore%20notes.md)\n\n## Docker Support\nIf you don't want to use a hosting service, you can host using [Docker](notes/docker.md) instead!\nI would *not use this method* unless you know what you are doing.\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6: 🎨 [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":["setup"]},"/notes/ignore-notes":{"title":"Ignoring Notes","content":"\n### Quartz Ignore\nEdit `ignoreFiles` in `config.toml` to include paths you'd like to exclude from being rendered.\n\n```toml\n...\nignoreFiles = [  \n    \"/content/templates/*\",  \n    \"/content/private/*\", \n    \"\u003cyour path here\u003e\"\n]\n```\n\n`ignoreFiles` supports the use of Regular Expressions (RegEx) so you can ignore patterns as well (e.g. ignoring all `.png`s by doing `\\\\.png$`).\nTo ignore a specific file, you can also add the tag `draft: true` to the frontmatter of a note.\n\n```markdown\n---\ntitle: Some Private Note\ndraft: true\n---\n...\n```\n\nMore details in [Hugo's documentation](https://gohugo.io/getting-started/configuration/#ignore-content-and-data-files-when-rendering).\n\n### Global Ignore\nHowever, just adding to the `ignoreFiles` will only prevent the page from being access through Quartz. If you want to prevent the file from being pushed to GitHub (for example if you have a public repository), you need to also add the path to the `.gitignore` file at the root of the repository.","lastmodified":"2023-04-18T08:00:06.367982973Z","tags":[]},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\nOpen Settings \u003e Files \u0026 Links and look for these two items:\n\n1. Set the **New link format** to **Absolute Path in vault**. If you have a completely flat vault (no folders), this step isn't necessary.\n2. Turn **on** the **Automatically update internal links** setting.\n\n\n![[notes/images/obsidian-settings.png]]*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n\u003e [!WARNING]\n\u003e \n\u003e **If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":["setup"]},"/notes/philosophy":{"title":"Quartz Philosophy","content":"\n\u003e “[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.” — Richard Hamming\n\n## Why Quartz?\nHosting a public digital garden isn't easy. There are an overwhelming number of tutorials, resources, and guides for tools like [Notion](https://www.notion.so/), [Roam](https://roamresearch.com/), and [Obsidian](https://obsidian.md/), yet none of them have super easy to use *free* tools to publish that garden to the world.\n\nI've personally found that\n1. It's nice to access notes from anywhere\n2. Having a public digital garden invites open conversations\n3. It makes keeping personal notes and knowledge *playful and fun*\n\nI was really inspired by [Bianca](https://garden.bianca.digital/) and [Joel](https://joelhooks.com/digital-garden)'s digital gardens and wanted to try making my own.\n\n**The goal of Quartz is to make hosting your own public digital garden free and simple.** You don't even need your own website. Quartz does all of that for you and gives your own little corner of the internet.\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":[]},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, the following\ninstructions guide you through installing the proper dependencies to run it locally.\n\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly (see [[notes/troubleshooting#`command not found: hugo-obsidian`|the troubleshooting page]])! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e [!INFO] Docker Support\n\u003e\n\u003e If you have the Docker CLI installed already, you can avoid installing `hugo-obsidian` and `hugo`. Instead, open your terminal, navigate to your folder with Quartz and run `make docker`\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated! Now, let's get it hosted online.\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":["setup"]},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://beta.operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Login or Register for a new Operand account. Click the verification link sent to your email, and you'll be redirected to the dashboard. (Note) You do not need to enter a credit card to create an account, or get started with the Operand API. The first $10 of usage each month is free. To learn more, see pricing. If you go over your free quota, we'll (politely) reach out and ask you to configure billing.\n2. Create your first index. On the dashboard, under \"Indexes\", enter the name and description of your index, and click \"Create Index\". Note down the ID of the index (obtained by clicking on the index name in the list of indexes), as you'll need it in the next step. IDs are unique to each index, and look something like `uqv1duxxbdxu`.\n3. Click into the index you've created. Under \"Index Something\", select \"SITEMAP\" from the dropdown and click \"Add Source\".\n4. For the \"Sitemap.xml URL\", put your deployed site's base URL followed by `sitemap.xml`. For example, for `quartz.jzhao.xyz`, put `https://quartz.jzhao.xyz/sitemap.xml`. Leave the URL Regex empty. \n5. Get your API key. On the dashboard, under \"API Keys\", you can manage your API keys. If you don't already have an API key, click \"Create API Key\". You'll need this for the next step.\n6. Open `data/config.yaml`. Set `enableSemanticSearch` to `true`, `operandApiKey` to your copied key, and `operandIndexId` to the ID of the index we created from earlier..\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nsearch:\n  enableSemanticSearch: true\n  operandApiKey: \"jp9k5hudse2a828z98kxd6z3payi8u90rnjf\"\n  operandIndexId: \"s0kf3bd6tldw\"\n```\n7. Push your changes to the site and wait for it to deploy.\n8. Check the Operand dashboard and wait for your site to index. Enjoy natural language search powered by Operand!\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":[]},"/notes/setup":{"title":"Setup","content":"\n## Making your own Quartz\nSetting up Quartz requires a basic understanding of `git`. If you are unfamiliar, [this resource](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is a great place to start!\n\n### Forking\n\u003e A fork is a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.\n\nNavigate to the GitHub repository for the Quartz project:\n\n📁 [Quartz Repository](https://github.com/jackyzha0/quartz)\n\nThen, Fork the repository into your own GitHub account. **Make sure that when you fork, you _uncheck_ the 'Copy the `hugo` branch only' option**.\n\nIf you don't have an account, you can make on for free [here](https://github.com/join). More details about forking a repo can be found on [GitHub's documentation](https://docs.github.com/en/get-started/quickstart/fork-a-repo).\n\n![[notes/images/fork.png]]\n\n### Cloning\nAfter you've made a fork of the repository, you need to download the files locally onto your machine. Ensure you have `git`, then type the following command in your terminal replacing `YOUR-USERNAME` with your GitHub username.\n\n```shell\ngit clone https://github.com/YOUR-USERNAME/quartz\n```\n\n## Editing\nGreat! Now you have everything you need to start editing and growing your digital garden. If you're ready to start writing content already, check out the recommended flow for editing notes in Quartz.\n\n\u003e ✏️ Step 2: [Editing Notes in Quartz](notes/editing.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":["setup"]},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary 🧠](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinterの数字花园](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n- [Abhijeet's Math Wiki](https://abhmul.github.io/quartz/Math-Wiki/)\n- [Mike's AI Garden 🤖🪴](https://mwalton.me/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":[]},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile (~/.zshrc if you are on Mac)\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile # again, (~/.zshrc if you are on Mac)\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup analytics?\nQuartz by default uses [Plausible](https://plausible.io/) for analytics. \n\nIf you would prefer to use Google Analytics, you can follow this [guide in the Hugo documentation](https://gohugo.io/templates/internal/#google-analytics). \n\nAlternatively, you can also import your Google Analytics data into Plausible by [following this guide](https://plausible.io/docs/google-analytics-import).\n\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\n🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":[]},"/notes/updating":{"title":"Updating","content":"\nHaven't updated Quartz in a while and want all the cool new optimizations? On Unix/Mac systems you can run the following command for a one-line update! This command will show you a log summary of all commits since you last updated, press `q` to acknowledge this. Then, it will show you each change in turn and press `y` to accept the patch or `n` to reject it. Usually you should press `y` for most of these unless it conflicts with existing changes you've made! \n\n```shell\nmake update\n```\n\nOr, if you don't want the interactive parts and just want to force update your local garden (this assumed that you are okay with some of your personalizations been overriden!)\n\n```shell\nmake update-force\n```\n\nOr, manually checkout the changes yourself.\n\n\u003e [!warning] Warning!\n\u003e\n\u003e If you customized the files in `data/`, or anything inside `layouts/`, your customization may be overwritten!\n\u003e Make sure you have a copy of these changes if you don't want to lose them.\n\n\n```shell\n# add Quartz as a remote host\ngit remote add upstream git@github.com:jackyzha0/quartz.git\n\n# index and fetch changes\ngit fetch upstream\ngit checkout -p upstream/hugo -- layouts .github Makefile assets/js assets/styles/base.scss assets/styles/darkmode.scss config.toml data \n```\n","lastmodified":"2023-04-18T08:00:06.371982983Z","tags":[]}}